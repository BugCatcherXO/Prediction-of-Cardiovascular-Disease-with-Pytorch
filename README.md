Predicci√≥n de Enfermedad Card√≠aca con PyTorch (MLP)

Proyecto de clasificaci√≥n binaria que, a partir de variables cl√≠nicas b√°sicas, predice la presencia de HeartDisease. Est√° implementado en un notebook con pandas / scikit-learn / PyTorch e incluye EDA, split estratificado, preprocessing sin fugas de informaci√≥n, entrenamiento de una MLP y evaluaci√≥n con ROC y Precision-Recall, adem√°s de b√∫squeda de umbral por F1.

üóÇ Estructura del proyecto
cardiovascular_illness/
‚îú‚îÄ 01_proyecto.ipynb
‚îî‚îÄ dataset/
   ‚îî‚îÄ heart.csv


üöÄ Requisitos e instalaci√≥n

Python 3.9+

Jupyter / IPython

Paquetes principales: pandas, numpy, matplotlib, scikit-learn, torch (CUDA opcional)

Instalaci√≥n r√°pida (Windows / macOS / Linux):

# (opcional) entorno virtual
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS / Linux
source .venv/bin/activate

pip install pandas numpy matplotlib scikit-learn torch jupyter


Abrir el notebook:

jupyter notebook 01_proyecto.ipynb

üì¶ Datos

Archivo: dataset/heart.csv
Target: HeartDisease ‚àà {0,1}
Features usadas: Age, Sex, ChestPainType, RestingBP, Cholesterol, FastingBS, RestingECG, MaxHR, ExerciseAngina, Oldpeak, ST_Slope.

El notebook arranca con una sanity check: shape, tipos, valores perdidos y distribuci√≥n del objetivo.

üîé EDA (Exploratory Data Analysis)

Incluye:

Histograma de la variable objetivo.

Histogramas y boxplots de variables num√©ricas.

Matriz de correlaciones (Pearson) para num√©ricas + target.

En EDA se excluye FastingBS de algunos gr√°ficos por ser binaria, pero s√≠ se utiliza como feature en el modelo.

‚úÇÔ∏è Split y Preprocessing

Split estratificado y reproducible (seed=42):

Train 70%, Valid 15%, Test 15%.

Sin fugas: estad√≠sticas de imputaci√≥n/estandarizaci√≥n se calculan solo en train.

Num√©ricas ‚Üí imputaci√≥n por mediana + z-score (media/STD de train; STD=1 si es 0).

Categ√≥ricas (Sex, ChestPainType, RestingECG, ExerciseAngina, ST_Slope) ‚Üí one-hot con columnas fijadas por train (reindex en val/test).

Tratamiento espec√≠fico: Cholesterol == 0 se considera missing y se imputa con la mediana.

üß† Modelo

MLP (PyTorch)

Capas: in_features ‚Üí 128 ‚Üí 32 ‚Üí 1

Activaci√≥n: ReLU

Dropout p=0.325

P√©rdida: BCEWithLogitsLoss

Optimizador: Adam lr=1e-3, weight_decay=1e-4

Batch size: 64

√âpocas: 250

Device: cuda si hay GPU, si no cpu

Semillas fijadas: numpy/torch (42)

Durante el entrenamiento se reportan por √©poca: train_loss, val_loss, val_acc, val_auroc, val_f1.

üìä Evaluaci√≥n y selecci√≥n de umbral

ROC en validaci√≥n
AUROC ‚âà 0.929 (seg√∫n la figura incluida).

Precision-Recall en validaci√≥n
AUPRC ‚âà 0.942.

Umbral √≥ptimo por F1 (validaci√≥n)
Se barre el umbral sobre las scores de validaci√≥n y se selecciona el que maximiza F1.

Reporte en test
Se imprimen m√©tricas a:

Umbral 0.5

Mejor umbral (F1-val)

Para cada caso: accuracy, precision, recall, F1, AUROC y matriz de confusi√≥n [[TN, FP],[FN, TP]]